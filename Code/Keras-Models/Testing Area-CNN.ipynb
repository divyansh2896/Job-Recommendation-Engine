{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D, Embedding, LSTM\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras import metrics, regularizers\n",
    "from keras.preprocessing import sequence\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load cleaned dataset\n",
    "data = pd.read_csv('../../Results/Cleaned_JobDescs.csv', header = 0, names = ['Query', 'Description'])\n",
    "#data = pd.read_csv('../../Results/Cleaned_JobsNonIT.csv', header = 0, names = ['Query', 'Description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the dataset to Training and Test subsets (90/10)\n",
    "train, test = train_test_split(data, test_size = 0.1, random_state = 17) #random_state = None\n",
    "\n",
    "train_descs = train['Description']\n",
    "train_labels = train['Query']\n",
    " \n",
    "test_descs = test['Description']\n",
    "test_labels = test['Query']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Parameters\n",
    "vocab_size = 1000\n",
    "\n",
    "sequences_length = 1200\n",
    "\n",
    "embedding_dimensionality = 32 #possibly low??\n",
    "max_features = 1000 #equal to vocab_size\n",
    "\n",
    "num_labels = len(train_labels.unique())\n",
    "batch_size = 64\n",
    "nb_epoch = 20\n",
    "\n",
    "nof_filters = 100 #check + research ... random now\n",
    "kernel_size = 16 #check + research ... random now\n",
    "\n",
    "hidden_dims = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Texts to Numeric Vectors for Input\n",
    "tokenizer = Tokenizer(num_words = vocab_size)\n",
    "tokenizer.fit_on_texts(train_descs)\n",
    "\n",
    "x_train = tokenizer.texts_to_sequences(train_descs)\n",
    "x_test = tokenizer.texts_to_sequences(test_descs)\n",
    "\n",
    "x_train = sequence.pad_sequences(x_train, maxlen = sequences_length, padding = 'post')\n",
    "x_test = sequence.pad_sequences(x_test, maxlen = sequences_length, padding = 'post')\n",
    "\n",
    "encoder = LabelBinarizer()\n",
    "encoder.fit(train_labels)\n",
    "y_train = encoder.transform(train_labels)\n",
    "y_test = encoder.transform(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 1200, 32)          32000     \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1185, 100)         51300     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 25)                1275      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 25)                0         \n",
      "=================================================================\n",
      "Total params: 89,625\n",
      "Trainable params: 89,625\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embedding_dimensionality, input_length = 1200))\n",
    "#model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "\n",
    "model.add(Conv1D(nof_filters, kernel_size, padding='valid', activation='relu', strides = 1))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "\n",
    "model.add(Dense(hidden_dims))\n",
    "# model.add(Dropout(0.2))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(num_labels))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', #'sgd', 'RMSprop', 'Adagrad'\n",
    "                   metrics = [metrics.categorical_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7200 samples, validate on 1800 samples\n",
      "Epoch 1/20\n",
      "7200/7200 [==============================] - 65s 9ms/step - loss: 3.1750 - categorical_accuracy: 0.0751 - val_loss: 2.9716 - val_categorical_accuracy: 0.1394\n",
      "Epoch 2/20\n",
      "7200/7200 [==============================] - 80s 11ms/step - loss: 2.5977 - categorical_accuracy: 0.2169 - val_loss: 2.2374 - val_categorical_accuracy: 0.3067\n",
      "Epoch 3/20\n",
      "7200/7200 [==============================] - 79s 11ms/step - loss: 1.9346 - categorical_accuracy: 0.4036 - val_loss: 1.7891 - val_categorical_accuracy: 0.4278\n",
      "Epoch 4/20\n",
      "7200/7200 [==============================] - 79s 11ms/step - loss: 1.5022 - categorical_accuracy: 0.5424 - val_loss: 1.5722 - val_categorical_accuracy: 0.5100\n",
      "Epoch 5/20\n",
      "7200/7200 [==============================] - 90s 13ms/step - loss: 1.2031 - categorical_accuracy: 0.6406 - val_loss: 1.3889 - val_categorical_accuracy: 0.5678\n",
      "Epoch 6/20\n",
      "7200/7200 [==============================] - 97s 13ms/step - loss: 0.9871 - categorical_accuracy: 0.7028 - val_loss: 1.3227 - val_categorical_accuracy: 0.5983\n",
      "Epoch 7/20\n",
      "7200/7200 [==============================] - 98s 14ms/step - loss: 0.8279 - categorical_accuracy: 0.7500 - val_loss: 1.3084 - val_categorical_accuracy: 0.6022\n",
      "Epoch 8/20\n",
      "7200/7200 [==============================] - 89s 12ms/step - loss: 0.6908 - categorical_accuracy: 0.7996 - val_loss: 1.2957 - val_categorical_accuracy: 0.6172\n",
      "Epoch 9/20\n",
      "7200/7200 [==============================] - 78s 11ms/step - loss: 0.5677 - categorical_accuracy: 0.8396 - val_loss: 1.2696 - val_categorical_accuracy: 0.6189\n",
      "Epoch 10/20\n",
      "7200/7200 [==============================] - 85s 12ms/step - loss: 0.4621 - categorical_accuracy: 0.8788 - val_loss: 1.3050 - val_categorical_accuracy: 0.6206\n",
      "Epoch 11/20\n",
      "7200/7200 [==============================] - 81s 11ms/step - loss: 0.3713 - categorical_accuracy: 0.9083 - val_loss: 1.3034 - val_categorical_accuracy: 0.6200\n",
      "Epoch 12/20\n",
      "7200/7200 [==============================] - 83s 12ms/step - loss: 0.2917 - categorical_accuracy: 0.9356 - val_loss: 1.3586 - val_categorical_accuracy: 0.6222\n",
      "Epoch 13/20\n",
      "7200/7200 [==============================] - 84s 12ms/step - loss: 0.2260 - categorical_accuracy: 0.9561 - val_loss: 1.3841 - val_categorical_accuracy: 0.6283\n",
      "Epoch 14/20\n",
      "7200/7200 [==============================] - 82s 11ms/step - loss: 0.1769 - categorical_accuracy: 0.9682 - val_loss: 1.4389 - val_categorical_accuracy: 0.6356\n",
      "Epoch 15/20\n",
      "7200/7200 [==============================] - 87s 12ms/step - loss: 0.1412 - categorical_accuracy: 0.9771 - val_loss: 1.4690 - val_categorical_accuracy: 0.6328\n",
      "Epoch 16/20\n",
      "7200/7200 [==============================] - 82s 11ms/step - loss: 0.1158 - categorical_accuracy: 0.9810 - val_loss: 1.5331 - val_categorical_accuracy: 0.6283\n",
      "Epoch 17/20\n",
      "7200/7200 [==============================] - 79s 11ms/step - loss: 0.0952 - categorical_accuracy: 0.9847 - val_loss: 1.5586 - val_categorical_accuracy: 0.6250\n",
      "Epoch 18/20\n",
      "7200/7200 [==============================] - 84s 12ms/step - loss: 0.0892 - categorical_accuracy: 0.9857 - val_loss: 1.5808 - val_categorical_accuracy: 0.6322\n",
      "Epoch 19/20\n",
      "7200/7200 [==============================] - 87s 12ms/step - loss: 0.0785 - categorical_accuracy: 0.9865 - val_loss: 1.6203 - val_categorical_accuracy: 0.6294\n",
      "Epoch 20/20\n",
      "7200/7200 [==============================] - 86s 12ms/step - loss: 0.0756 - categorical_accuracy: 0.9857 - val_loss: 1.6914 - val_categorical_accuracy: 0.6339\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size = batch_size,\n",
    "                    epochs = nb_epoch,\n",
    "                    verbose = True,\n",
    "                    validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 3s 3ms/step\n",
      "\n",
      "Test categorical_crossentropy: 1.6137231540679933\n",
      "Categorical accuracy: 0.64\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, batch_size = batch_size, verbose = True)\n",
    " \n",
    "print('\\nTest categorical_crossentropy:', score[0])\n",
    "print('Categorical accuracy:', score[1])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
