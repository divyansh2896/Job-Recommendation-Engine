{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "from bs4 import BeautifulSoup\n",
    "from html2text import html2text\n",
    "import pandas as pd\n",
    "import pprint as pp\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract Job URL Function\n",
    "def extract_job_url_from_result(soup): \n",
    "    urls = []\n",
    "    for div in soup.find_all(name = \"div\", attrs = {\"class\":\"row\"}):\n",
    "        for a in div.find_all(name = \"a\", attrs = {\"data-tn-element\":\"jobTitle\"}):\n",
    "            this_url = a['href']\n",
    "            to_go_url = \"https://www.indeed.com/viewjob\" + this_url[7:]\n",
    "            urls.append(to_go_url)\n",
    "    return(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract Job Title & Description\n",
    "def extract_text_from_jobURL(url):\n",
    "    \n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "    \n",
    "    #Retrive the job title\n",
    "    b = soup.find('b','jobtitle')\n",
    "    if b != None:\n",
    "        \n",
    "        #Retrive the job description\n",
    "        table = soup.find('table', id = 'job-content')\n",
    "        span = table.find('span', id = 'job_summary')\n",
    "\n",
    "        div = span.find('div')\n",
    "\n",
    "        #Because in some posts there isn't exist the div class\n",
    "        if div==None:\n",
    "            div=span\n",
    "\n",
    "        #Cleaning (remove newllines, * , spaces)\n",
    "        b=html2text(str(b)).replace(\" \", \"\").replace(\"*\",\"\").replace(\"\\n\",\"\")\n",
    "        div=html2text(str(div)).replace(\" \", \"\").replace(\"*\",\"\").replace(\"\\n\",\"\")\n",
    "    \n",
    "        return(b,div)\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        return([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the Job Title Dataset\n",
    "job_titles=pd.read_csv(\"..\\Datasets\\Job_Titles.csv\", sep = \",\")\n",
    "\n",
    "#Create job_titles list\n",
    "job_list=list(job_titles.Job_titles)\n",
    "\n",
    "#Replace spaces with '+'\n",
    "job_list2=[]\n",
    "for item in job_list:\n",
    "    job_list2.append(item.replace(' ', '+'))\n",
    "    \n",
    "job_list=job_list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create URLs\n",
    "\n",
    "#Initialize the url job list and city list\n",
    "url_list=[]\n",
    "city_list=['New+York','England']\n",
    "\n",
    "for city in city_list:\n",
    "    for job in job_list:\n",
    "        for start in range(0,20,10):\n",
    "            URL=\"http://www.indeed.com/jobs?q=\"+ job + \"%2420%2C000&l=\" + str(city) + \"&start=\" + str(start)\n",
    "            url_list.append(URL)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main loop\n",
    "\n",
    "#Initialize the dataframe\n",
    "columns=[\"job_title\",\"job_description\"]\n",
    "df = pd.DataFrame(columns = columns)\n",
    "n=0\n",
    "\n",
    "#Extract the information from the site\n",
    "for i in url_list:\n",
    "\n",
    "    #Conducting a request of the stated URL above:\n",
    "    page = requests.get(i)\n",
    "    \n",
    "    #Add 1 second sleep\n",
    "    time.sleep(0.3)\n",
    "    \n",
    "    #Specifying a desired format of “page” using the html parser\n",
    "    soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "\n",
    "    #Go to job page\n",
    "    extract_job=extract_job_url_from_result(soup)\n",
    "    \n",
    "    #Check if there is a job in indeed\n",
    "    if extract_job !=[]:\n",
    "        job_url = extract_job[0]\n",
    "        \n",
    "        #Extract job description (remove newllines, * , spaces)\n",
    "        job_description=extract_text_from_jobURL(job_url)\n",
    "\n",
    "        #Add a new row\n",
    "        if job_description !=[]:\n",
    "            df.loc[len(df)]=[job_description[0],job_description[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a csv file\n",
    "df.to_csv(\"Initial_Job_Df.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
